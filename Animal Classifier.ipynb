{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Deps\n",
    "Which are provided by tensorpad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Allows access to the file system\n",
    "import os\n",
    "\n",
    "# Provides an API for scientific computing\n",
    "import numpy as np\n",
    "\n",
    "# Allows us to render images and plot data\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning framework that provides an abstract API on top of Tensorflow\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, LambdaCallback, ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "# Allows use to timestamp the training run\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the graph which is used for rendering the images\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_labels(dir):\n",
    "    \"\"\"\n",
    "    Gets the name of each directory in the directory.\n",
    "    \n",
    "    dir: Directory which holds directories.\n",
    "    return: An array of the names of the directories in dir.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all directories in this directory\n",
    "    classes = os.listdir(dir)\n",
    "    \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_images(classes, dir):\n",
    "    \"\"\"\n",
    "    Gets the paths of all images in each directory.\n",
    "    \n",
    "    classes: Name of each class.\n",
    "    dir: Directory which holds directories.\n",
    "    return: A 2d array of paths organized by class name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an array to hold the image paths of each class\n",
    "    class_paths = []\n",
    "\n",
    "    # Create image paths of each class\n",
    "    for label in classes:\n",
    "        \n",
    "        # Create an array to hold the image paths of this class (label)\n",
    "        image_paths = np.array([])\n",
    "\n",
    "        # Create the path of this class\n",
    "        class_path = os.path.join(dir, label)\n",
    "\n",
    "        # Get all images in this directory\n",
    "        images = os.listdir(class_path)\n",
    "\n",
    "        # Create the path of each images in this class\n",
    "        for image in images:\n",
    "            \n",
    "            # Create the path of this image\n",
    "            image_path = os.path.join(class_path, image)\n",
    "\n",
    "            # Add the image path to the image paths array\n",
    "            image_paths = np.append(image_paths, image_path)\n",
    "\n",
    "        # Add the image paths to the class paths array\n",
    "        class_paths.append(image_paths)\n",
    "        \n",
    "    return class_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_fig(h, w):\n",
    "    fig = plt.figure(figsize=(h, w), tight_layout=True)\n",
    "    fig.set_facecolor('white')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(cols, fig, image_path, subplot_index, subplot_label):\n",
    "    \"\"\"\n",
    "    Loads an image from a path, then renders it to the figure with a label\n",
    "    \n",
    "    cols: total number of images to be plotted, if calling this many times for a figure\n",
    "    fig: figure to plot the image onto\n",
    "    image_path: path to the image to be plotted\n",
    "    subplot_index: Index describing where in the figure the image should be plotted\n",
    "    subplot_label: Label for the subplot\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the image\n",
    "    # pip install pillow may be required\n",
    "    image_pil = load_img(image_path, interpolation='nearest', target_size=(200,200))\n",
    "        \n",
    "    # render an image to the plot\n",
    "    ax = fig.add_subplot(1, cols, subplot_index)\n",
    "    ax.imshow(image_pil)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(subplot_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(image_path):\n",
    "    image_pil = load_img(image_path, interpolation='nearest', target_size=(image_dim, image_dim, 3))\n",
    "    image_arr = img_to_array(image_pil)\n",
    "\n",
    "    image = np.array([image_arr])\n",
    "    \n",
    "    prediction = model.predict(image, batch_size=1)\n",
    "    subplot_label = \"Prediction: \" + str(prediction)\n",
    "    \n",
    "    fig = setup_fig(7, 7)\n",
    "    plot_image(1, fig, image_path, 1, subplot_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset should be a set of images in a nested structure. \n",
    "# The root directory should hold them all. In the root directory should be several directories.\n",
    "# Each directory should have the name of the class (cat) of images it holds.\n",
    "# In each directory should be images of the same class (cat images).\n",
    "\n",
    "# Crawl the dataset directory and create an array for y, image labels (directory name), \n",
    "# and x, image (image path)\n",
    "train_dir = 'dataset/train'\n",
    "validate_dir = 'dataset/validate'\n",
    "predict_dir = 'dataset/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# the number of pixels for the width and height of the image\n",
    "image_dim = 200\n",
    "\n",
    "# the size of the image (h,w,c)\n",
    "input_shape = (image_dim, image_dim, 3)\n",
    "\n",
    "# the rate which the model learns\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# size of each mini-batch\n",
    "batch_size = 16\n",
    "\n",
    "# nunmber of training episodes\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory which we will save training outputs to\n",
    "# add a timestamp so that tensorboard show each training session as a different run\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "output_logs_dir = 'logs/' + timestamp + '-' + str(batch_size) + '-' + str(epochs) + '-' + str(image_dim)\n",
    "\n",
    "# directory to save the model\n",
    "model_name = 'trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# define data generators\n",
    "train_data_generator = ImageDataGenerator()\n",
    "validation_data_generator = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory(train_dir,\n",
    "                                                          target_size=(image_dim, image_dim),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_directory(validate_dir,\n",
    "                                                          target_size=(image_dim, image_dim),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'butterfly': 0, 'cat': 1, 'chicken': 2, 'cow': 3, 'dog': 4, 'elephant': 5, 'horse': 6, 'sheep': 7, 'spider': 8, 'squirrel': 9}\n"
     ]
    }
   ],
   "source": [
    "# Examine how the classes are arranged\n",
    "classes_dictionary = train_generator.class_indices\n",
    "print(classes_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "- How to mount dataset\n",
    "- Directory\n",
    "- Y = classes\n",
    "- X = image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of each directory in the root directory and store them as an array.\n",
    "# These are the classes.\n",
    "classes = get_class_labels(predict_dir)\n",
    "\n",
    "# Get the number of classes\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Get the paths of all the images in each class directory and store them as a 2d array.\n",
    "# These are the class images paths.\n",
    "image_paths = get_class_images(classes, predict_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example dataset\n",
    "- Diplay name of all classes\n",
    "- Display at 1 image from each class \n",
    "- with class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Display the name of all the classes\n",
    "print(\"Classes: \" + str(classes))\n",
    "\n",
    "# Display the number of classes\n",
    "print(\"Number of classes: \" + str(n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model\n",
    "- Use keras\n",
    "- Input = image as [64x64x3]?\n",
    "- Based on VVG16?\n",
    "- Output = [10]\n",
    "- loss\n",
    "- optimizer\n",
    "- compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# takes in images, convoles them, flattens them, classifies them\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "#     Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "#     Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer and loss to use\n",
    "model.compile(optimizer=optimizers.SGD(lr=learning_rate, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 28,290,634\n",
      "Trainable params: 28,290,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# look at the defined model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validate the model\n",
    "- Use x epochs\n",
    "- Use x batchsize\n",
    "- Save model every 10 epochs\n",
    "- Generate 10 predictions every 10 epochs\n",
    "- Display predicted label and actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log information for use with tensorboard\n",
    "tensorboard = TensorBoard(log_dir=output_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a callback to make a prediction\n",
    "predict = LambdaCallback(on_epoch_end=lambda epoch, logs: prediction(image_paths[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 2.3821 - acc: 0.1250"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=800/batch_size,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=200,\n",
    "                    epochs=epochs,\n",
    "#                     callbacks=[predict, tensorboard])\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view tensorboard with http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model for later\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "- Make 100 predictions\n",
    "- Display predicted label, actual label, and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in image_paths:\n",
    "    prediction(image_path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "- Training time on desktop\n",
    "- Training time on colab\n",
    "- Training time on tensorpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
