{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Deps\n",
    "Which are provided by tensorpad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Allows access to the file system\n",
    "import os\n",
    "\n",
    "# Provides an API for scientific computing\n",
    "import numpy as np\n",
    "\n",
    "# Allows us to render images and plot data\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning framework that provides an abstract API on top of Tensorflow\n",
    "import keras\n",
    "from keras.callbacks import LambdaCallback, TensorBoard\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "# Allows use to timestamp the training run\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the matplotlib for jupyter notebooks, used for rendering the images\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_labels(dir):\n",
    "    \"\"\"\n",
    "    Gets the name of each directory in the directory.\n",
    "    \n",
    "    dir: Directory which holds directories.\n",
    "    return: An array of the names of the directories in dir.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all directories in this directory\n",
    "    classes = os.listdir(dir)\n",
    "    \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_images(classes, dir):\n",
    "    \"\"\"\n",
    "    Gets the paths of all images in each directory.\n",
    "    \n",
    "    classes: Name of each class.\n",
    "    dir: Directory which holds directories.\n",
    "    return: A 2d array of paths organized by class name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an array to hold the image paths of each class\n",
    "    class_paths = []\n",
    "\n",
    "    # Create image paths of each class\n",
    "    for label in classes:\n",
    "        \n",
    "        # Create an array to hold the image paths of this class (label)\n",
    "        image_paths = np.array([])\n",
    "\n",
    "        # Create the path of this class\n",
    "        class_path = os.path.join(dir, label)\n",
    "\n",
    "        # Get all images in this directory\n",
    "        images = os.listdir(class_path)\n",
    "\n",
    "        # Create the path of each images in this class\n",
    "        for image in images:\n",
    "            \n",
    "            # Create the path of this image\n",
    "            image_path = os.path.join(class_path, image)\n",
    "\n",
    "            # Add the image path to the image paths array\n",
    "            image_paths = np.append(image_paths, image_path)\n",
    "\n",
    "        # Add the image paths to the class paths array\n",
    "        class_paths.append(image_paths)\n",
    "        \n",
    "    return class_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_fig(h, w):\n",
    "    fig = plt.figure(figsize=(h, w), tight_layout=True)\n",
    "    fig.set_facecolor('white')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(cols, fig, image_path, subplot_index, subplot_label):\n",
    "    \"\"\"\n",
    "    Loads an image from a path, then renders it to the figure with a label\n",
    "    \n",
    "    cols: total number of images to be plotted, if calling this many times for a figure\n",
    "    fig: figure to plot the image onto\n",
    "    image_path: path to the image to be plotted\n",
    "    subplot_index: Index describing where in the figure the image should be plotted\n",
    "    subplot_label: Label for the subplot\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the image\n",
    "    # pip install pillow may be required\n",
    "    image_pil = load_img(image_path, interpolation='nearest', target_size=(200,200))\n",
    "        \n",
    "    # render an image to the plot\n",
    "    ax = fig.add_subplot(1, cols, subplot_index)\n",
    "    ax.imshow(image_pil)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(subplot_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(image_path, class_keys):\n",
    "    # load the image\n",
    "    image_pil = load_img(image_path, interpolation='nearest', target_size=(image_dim, image_dim, 3))\n",
    "    \n",
    "    # turn it into an array\n",
    "    image_arr = img_to_array(image_pil)\n",
    "    \n",
    "    # turn it into a numpy array so that it can be feed into the model as a batch\n",
    "    image = np.array([image_arr])\n",
    "    \n",
    "    # make a prediction on the batch\n",
    "    prediction = model.predict(image, batch_size=1)\n",
    "    \n",
    "    # determine the most likely class from the prediction\n",
    "    most_likely_class = np.argmax(prediction[0])\n",
    "    \n",
    "    # add class labels for the prediction\n",
    "    # remember that we feed in a batch so we need to grab the first prediction\n",
    "    prediction_classes = [str(class_keys[index]) + \": \" + str(round(prob*100, 4)) + \"%\" for index, prob in enumerate(prediction[0])]\n",
    "    \n",
    "    # generate the prediction label\n",
    "    subplot_label = \"Prediction: \" + str(class_keys[most_likely_class]) + \"\\nProbabilities: \" + ', '.join(prediction_classes)\n",
    "    \n",
    "    # setup a plot and plot the image\n",
    "    fig = setup_fig(7, 7)\n",
    "    plot_image(1, fig, image_path, 1, subplot_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset should be a set of images in a nested structure. \n",
    "# The root directory should hold them all. In the root directory should be several directories.\n",
    "# Each directory should have the name of the class (cat) of images it holds.\n",
    "# In each directory should be images of the same class (cat images).\n",
    "\n",
    "# Crawl the dataset directory and create an array for y, image labels (directory name), \n",
    "# and x, image (image path)\n",
    "train_dir = 'dataset/train'\n",
    "validate_dir = 'dataset/validate'\n",
    "predict_dir = 'dataset/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# the number of pixels for the width and height of the image\n",
    "image_dim = 200\n",
    "\n",
    "# the size of the image (h,w,c)\n",
    "input_shape = (image_dim, image_dim, 3)\n",
    "\n",
    "# the rate which the model learns\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# size of each mini-batch\n",
    "batch_size = 32\n",
    "\n",
    "# nunmber of training episodes\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory which we will save training outputs to\n",
    "# add a timestamp so that tensorboard show each training session as a different run\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "output_logs_dir = 'logs/' + timestamp + '-' + str(batch_size) + '-' + str(epochs) + '-' + str(image_dim)\n",
    "\n",
    "# directory to save the model\n",
    "model_name = 'trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# define data generators\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          fill_mode='nearest')\n",
    "validation_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                               fill_mode='nearest')\n",
    "\n",
    "# tell the data generators to use data from the train and validation directories\n",
    "train_generator = train_data_generator.flow_from_directory(train_dir,\n",
    "                                                          target_size=(image_dim, image_dim),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_data_generator.flow_from_directory(validate_dir,\n",
    "                                                          target_size=(image_dim, image_dim),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine how the classes are arranged\n",
    "classes_dictionary = train_generator.class_indices\n",
    "\n",
    "# turn classes dictionary into an array of keys\n",
    "class_keys = list(classes_dictionary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of each directory in the root directory and store them as an array.\n",
    "# These are the classes.\n",
    "classes = get_class_labels(predict_dir)\n",
    "\n",
    "# Get the number of classes\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Get the paths of all the images in each class directory and store them as a 2d array.\n",
    "# These are the class images paths.\n",
    "image_paths = get_class_images(classes, predict_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# takes in images, convoles them, flattens them, classifies them\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer and loss to use\n",
    "model.compile(optimizer=optimizers.SGD(lr=learning_rate, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 32)      4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                400010    \n",
      "=================================================================\n",
      "Total params: 472,090\n",
      "Trainable params: 472,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# look at the defined model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log information for use with tensorboard\n",
    "tensorboard = TensorBoard(log_dir=output_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a callback to make a prediction\n",
    "predict = LambdaCallback(on_epoch_end=lambda epoch, logs: prediction(image_paths[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "250/250 [==============================] - 136s 543ms/step - loss: 2.3019 - acc: 0.1077 - val_loss: 2.2983 - val_acc: 0.1277\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 138s 552ms/step - loss: 2.2973 - acc: 0.1217 - val_loss: 2.2943 - val_acc: 0.1574\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 140s 559ms/step - loss: 2.2928 - acc: 0.1406 - val_loss: 2.2887 - val_acc: 0.1522\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 139s 554ms/step - loss: 2.2861 - acc: 0.1551 - val_loss: 2.2796 - val_acc: 0.1644\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 138s 552ms/step - loss: 2.2744 - acc: 0.1705 - val_loss: 2.2632 - val_acc: 0.1865\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 139s 558ms/step - loss: 2.2543 - acc: 0.1781 - val_loss: 2.2400 - val_acc: 0.1714\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 140s 558ms/step - loss: 2.2348 - acc: 0.1791 - val_loss: 2.2228 - val_acc: 0.1767\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 140s 558ms/step - loss: 2.2171 - acc: 0.1826 - val_loss: 2.2101 - val_acc: 0.2045\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 139s 557ms/step - loss: 2.2027 - acc: 0.1886 - val_loss: 2.2029 - val_acc: 0.1929\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 141s 562ms/step - loss: 2.1878 - acc: 0.2041 - val_loss: 2.1880 - val_acc: 0.2165\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 141s 562ms/step - loss: 2.1729 - acc: 0.2096 - val_loss: 2.1714 - val_acc: 0.2206\n",
      "Epoch 12/40\n",
      "248/250 [============================>.] - ETA: 0s - loss: 2.1537 - acc: 0.2194"
     ]
    }
   ],
   "source": [
    "# train the model using the training data generator\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=math.floor(8000/batch_size),\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=2000,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view tensorboard with http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model for later\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "- Make 100 predictions\n",
    "- Display predicted label, actual label, and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in image_paths:\n",
    "    prediction(image_path[0], class_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
